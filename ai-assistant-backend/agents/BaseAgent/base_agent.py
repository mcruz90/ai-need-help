import json
from typing import List, Dict, Any, AsyncGenerator
from utils.utils import logger
from llm_models.chat import chat_model
from agents.triage.triage_utils import Citation, CitationHandler, StreamHandler

class BaseAgent():
    def __init__(self, tools: List[Dict[str, Any]], functions_map: Dict[str, Any], name: str = "Agent"):
        self.tools = tools
        self.functions_map = functions_map
        self.messages = []
        self.name = name

    def initialize_messages(self, chat_history: List[Dict[str, str]], query: str) -> List[Dict[str, Any]]:

        system_prompt = f"""
        ## Task & Context
        You are an agent designed to perform a specific task.

        ## Instructions
        You will be given a user query and must use the available tools to perform the task.
        
        ## Tools
        You have access to the following tools:
        {self.tools}
        
        ## Output
        You will be provided with instructions on how to output your response.
        
        ## Parameters Strategy
        You will be given a strategy for how to form the best parameters for the tool calls.
        """

        self.messages = [
            {"role": "system", "content": system_prompt},
            *chat_history,
            {"role": "user", "content": query}
        ]

    async def generate_tool_results(self) -> List[Dict[str, Any]]:
        """
        Generate tool calls based on the messages.
        """
        response = await chat_model.generate_response_with_tools(self.messages, self.tools)

        self.messages.append(
                {
                    "role": "assistant",
                    "tool_calls": response.message.tool_calls,
                    "tool_plan": response.message.tool_plan,
                }
            )
        if response.message.tool_calls:
            for tc in response.message.tool_calls:
                try:
                    logger.info(f"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}")
                    tool_result = await self.functions_map[tc.function.name](**json.loads(tc.function.arguments))
                    if isinstance(tool_result, dict) and "error" in tool_result:
                        logger.error(f"Error from {tc.function.name}: {tool_result['error']}")
                        return {"error": f"An error occurred: {tool_result['error']}"}
                    
                    
                    tool_content = []
                    for data in tool_result:
                        tool_content.append({"type": "document", "document": {"data": json.dumps(data)}})
                
                    self.messages.append(
                        {"role": "tool", "tool_call_id": tc.id, "content": tool_content}
                    )

                except Exception as e:
                    logger.error(f"Error calling {tc.function.name}: {str(e)}")
                    return {"error": f"An error occurred while processing your request: {str(e)}"}
                
            logger.info(f"Tool results that will be used by the {self.name} to generate the final response")
            for result in tool_content:
                logger.info(result)
        else:
            logger.info(f"No tool results were generated by the {self.name}")
            logger.info(f"Using direct response text: {response.message.content[0].text}")
            self.messages.append({"role": "assistant", "content": response.message.content[0].text})
        

    async def analyze_tool_calls(self, query: str) -> str:
        """
        Analyze the tool calls to ensure that all aspects of the user's query are covered.
        """
        logger.info(f"Starting analyze_tool_calls for query: {query[:50]}...")

        prompt = f"""
        ## Task & Context
        Analyze the user's input and resulting tool calls in the provided chat history to
        extract key information to help inform the final response.

        User Query: "{query}"
        Chat history: "{self.messages}"

        ## Instructions
        Focus on analyzing the following:
        - Does the information retrieved answer all aspects of the user's query?
        - Was there any missing information that should have been retrieved in the tool calls?
        - Was there any information in the tool calls that is not relevant to the query?
        - Was there any information in the tool calls that is unclear or confusing?
        - Was there any information in the tool calls that is outdated?
        - Are the 5 W's (Who, What, When, Where, Why) applicable to the query covered in the tool calls?

        Do NOT attempt to answer the query. Instead, provide a brief, structured summary of the key points that will help inform the final response.

        ## Output
        Provide your analysis in the following format, but be concise and to the point:
        - Summary: A brief, structured summary of the key points.
        - Missing Information: A list of missing information that should have been retrieved in the tool calls.
        - Outdated Information: A list of outdated information that should have been retrieved in the tool calls.
        - Unclear Information: A list of unclear information that should have been retrieved in the tool calls.
        - Irrelevant Information: A list of irrelevant information that should have been retrieved in the tool calls.
        - Possible Improvements: A list of possible improvements to the tool calls.
        - Confidence Score: Rate the confidence in the analysis on a scale of 0 to 1.
        """

        context_messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": query}
        ]
        
        try:
            response = await chat_model.generate_response(context_messages)
            
        except Exception as e:
            logger.error(f"Error extracting key info: {e}")
            return "Error extracting key info"

        return response.message.content[0].text

    async def generate_final_response(self, query: str) -> AsyncGenerator[Dict[str, Any], None]:

        tool_call_analysis = await self.analyze_tool_calls(query)

        updated_instructions =  f"""
                ## Task & Context
                You have just received the results of your tool calls, and will now be asked to provide a final response to the user.
                Your final response must be based on the tool results provided and the analysis of the tool calls.

                ## User Query
                {query}

                ## Tool Call Analysis
                {tool_call_analysis}

                ## Instructions
                The tool results contain the answer to the user's question. Your task is to use this information to generate a final response to the user query.
                If the tool calls were not able to provide any relevant information, you should state that you are not able to answer the query and ask for more information or if you are able to help with something else.
                Make sure that your final response addresses all aspects of the user's query. Given the tool call analysis, you should adjust your response
                to address any aspect of the user's query that was missed as a result of the tools not being able to find the information.

                ## Style Guidelines
                - Be concise and to the point if the complexity of the user's request is low.
                - Be detailed and comprehensive if the complexity of the user's request is high.
                - Be kind and helpful, and maintain a professional tone.
                """
        
        self.messages.append({"role": "assistant", "content": updated_instructions})

        response_stream = await chat_model.generate_streaming_response(
            messages=self.messages,
            tools=self.tools
        )

        return response_stream

    async def generate_final_response_stream(self, response_stream: List[Dict[str, Any]]) -> AsyncGenerator[Dict[str, Any], None]:

        full_response = ""
        citations: List[Citation] = []

        # Properly format and stream the final raw response and the cited response back to the triage agent
        async def response_generator():
            nonlocal full_response, citations
            logger.info("Starting response generation")
            async for chunk in StreamHandler.stream_with_timeout(response_stream, timeout=10.0):
                if chunk and chunk.type == "content-delta":
                    content = chunk.delta.message.content.text
                    if content:
                        full_response += content
                        logger.debug(f"Content chunk received: {content}")
                        yield {"type": "content", "data": content}
                elif chunk and chunk.type == "citation-start":
                    citation = Citation(
                        start=chunk.delta.message.citations.start,
                        end=chunk.delta.message.citations.end,
                        text=chunk.delta.message.citations.text,
                        sources=chunk.delta.message.citations.sources
                    )
                    citations.append(citation)
                    logger.info(f"Citation received: {citation.to_dict()}")
                    yield {"type": "citation", "data": citation.to_dict()}
                elif chunk and chunk.type in ["message-start", "content-start", "citation-end", "content-end", "message-end"]:
                    logger.debug(f"Received chunk type: {chunk.type}")
                else:
                    logger.warning(f"Unexpected chunk type received: {chunk.type}")
            
            logger.info("Response generation completed")
            logger.info(f"Full response: {full_response}")
            logger.info(f"Citations: {[c.to_dict() for c in citations]}")
            
            try:
                cited_response, url_to_index = CitationHandler.add_citations_to_response(full_response, citations)
                logger.info(f"Cited response: {cited_response}")
                logger.info(f"URL to index mapping: {url_to_index}")

                yield {"type": "full_response", "data": full_response}
                yield {"type": "cited_response", "data": cited_response}
                yield {"type": "url_to_index", "data": url_to_index}
            except Exception as e:
                logger.error(f"Error in adding citations to response: {str(e)}")
                yield {"type": "error", "data": str(e)}

        return response_generator()